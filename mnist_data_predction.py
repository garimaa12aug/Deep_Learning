# -*- coding: utf-8 -*-
"""Deep_Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yv-eWq6qdZi2aDVIYijWOb_tE6w2uGGo
"""

import tensorflow as tf
import tensorflow.keras as keras
import numpy as np
import matplotlib.pyplot as plt
#loading the dataset
mnist = tf.keras.datasets.mnist
(x_train,y_train),(x_test,y_test)=mnist.load_data()

#printing 0th image 
print(x_train[0])
plt.imshow(x_train[0],cmap='gray')
plt.show()
print(y_train[0])
 
#printing the 198th image
print(x_train[198])
plt.imshow(x_train[198],cmap='gray')
plt.show()
print(y_train[198])

#normalize the data
x_train= tf.keras.utils.normalize(x_train)
x_test = tf.keras.utils.normalize(x_test)

#printing 0th image 
print(x_train[0])
plt.imshow(x_train[0],cmap='gray')
plt.show()
print(y_train[0])
 
#printing the 198th image
print(x_train[198])
plt.imshow(x_train[198],cmap='gray')
plt.show()
print(y_train[198])

#building the model
model=tf.keras.models.Sequential()
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(128,activation = tf.nn.relu))
model.add(tf.keras.layers.Dense(128,activation = tf.nn.relu))
model.add(tf.keras.layers.Dense(10,activation = tf.nn.softmax))

#compiling the model
model.compile(optimizer='adam',loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])

#fit the model
model.fit(x_train,y_train,epochs=3)

#evaluate the loss and accuracy
val_loss,val_acc=model.evaluate(x_test,y_test)
print( val_loss)
print( val_acc)

#save the model
model.save('num_read.model')

#load the model
new_model = tf.keras.models.load_model('num_read.model')

#prediction and printing
prediction = new_model.predict(x_test)
print(prediction)
print(np.argmax(prediction[0]))
plt.imshow(x_test[0],cmap='gray')
plt.show()